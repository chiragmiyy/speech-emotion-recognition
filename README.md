# üé§ Speech Emotion Recognition

A machine learning and deep learning-based system for recognizing emotions from speech using audio features like MFCCs, Spectrograms, and more.

## üìå Overview

This project implements a Speech Emotion Recognition (SER) pipeline that uses audio signal processing and classification algorithms to detect emotions from speech. It supports multiple datasets, feature extractors, classifiers, and evaluation metrics.

---

## üß† Supported Emotions

- Neutral
- Calm
- Happy
- Sad
- Angry
- Fearful
- Disgust
- Pleasant Surprise
- Boredom

---

## üõ†Ô∏è Features

- üîâ Extracts audio features (MFCC, Chromagram, Spectrogram, etc.)
- ü§ñ Classifiers: SVC, RandomForest, GradientBoosting, KNeighbors, MLP, RNN
- üß™ Hyperparameter tuning via GridSearchCV
- üìä Evaluation: Accuracy, Confusion Matrix
- üíæ Model saving & loading (`.pkl`)
- üîç Dataset support: RAVDESS, TESS, EMO-DB, Custom

---

## üì¶ Tech Stack

| Domain | Tools |
|--------|-------|
| Programming | Python |
| Audio Processing | Librosa, OpenSMILE |
| Machine Learning | Scikit-learn |
| Deep Learning | PyTorch, HuggingFace Transformers (Wav2Vec2) |
| Deployment (Optional) | Firebase Functions, Streamlit, Gradio |

---

## üìÅ Project Structure

```bash
speech-emotion-recognition/
‚îú‚îÄ‚îÄ data/                         # Raw and processed audio files, organized by dataset
‚îÇ   ‚îú‚îÄ‚îÄ RAVDESS/
‚îÇ   ‚îú‚îÄ‚îÄ TESS/
‚îÇ   ‚îú‚îÄ‚îÄ CREMA-D/
‚îÇ   ‚îî‚îÄ‚îÄ custom/                   # Your own audio recordings
‚îÇ
‚îú‚îÄ‚îÄ models/                       # Trained models & preprocessed data
‚îÇ   ‚îú‚îÄ‚îÄ final_model.pkl
‚îÇ   ‚îú‚îÄ‚îÄ scaler.pkl
‚îÇ   ‚îú‚îÄ‚îÄ label_encoder.pkl
‚îÇ   ‚îú‚îÄ‚îÄ tess-model.pkl
‚îÇ   ‚îî‚îÄ‚îÄ tess-label-encoder.pkl    # Any .joblib or .pt files
‚îÇ
‚îú‚îÄ‚îÄ results/                      # Visual outputs
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.png
‚îÇ   ‚îú‚îÄ‚îÄ model_accuracy_comparison.png
‚îÇ
‚îú‚îÄ‚îÄ src/                          # Source code
‚îÇ   ‚îî‚îÄ‚îÄfeatures.py                # Feature extraction scripts
‚îú‚îÄ‚îÄ train_final_model.py          # Training & evaluation logic
‚îú‚îÄ‚îÄ app.py                        # Streamlit-based app to demo emotion predictions
‚îú‚îÄ‚îÄ .gitattributes                # Optional: Git LFS or text encoding rules
‚îú‚îÄ‚îÄ CITATION.cff                  # Software citation metadata (you-only version)
‚îú‚îÄ‚îÄ LICENSE                       # MIT License (under your name)
‚îú‚îÄ‚îÄ README.md                     # Main project overview and usage
‚îú‚îÄ‚îÄ requirements.txt              # Python dependencies
‚îú‚îÄ‚îÄ streamlit_app.py              # App interface for demo/testing
‚îú‚îÄ‚îÄ plot_benchmarks.py            # Script to generate accuracy and confusion matrix plots
```

---

## üöÄ Getting Started

1. Clone the repo

git clone https://github.com/chirgamiyy/speech-emotion-recognition.git
cd speech-emotion-recognition

2. Install dependencies
   
pip install -r requirements.txt

3. Run training or prediction
   
python src/train.py        # Train model
python src/predict.py      # Predict emotion from audio

---

## üìä Example Results

### üîπ Model Accuracy Comparison (93.96%)
![Model Accuracy](./results/model_accuracy_comparison.png)

### üîπ Confusion Matrix (on Combined Dataset)
![Confusion Matrix](./results/confusion_matrix.png)

---

## üìú License

This project is licensed under the [MIT License](./LICENSE).

---

## üôå Acknowledgements
  
- **Audio Datasets**:
  - [RAVDESS on Kaggle](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio)
  - [TESS on Kaggle](https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess)
  - [CREMA-D on Kaggle](https://www.kaggle.com/datasets/ejlok1/cremad)

- **Feature Extraction Libraries**:
  - [Librosa](https://librosa.org/)
  - [OpenSMILE Toolkit](https://audeering.github.io/opensmile/)

- **Machine Learning & Deep Learning**:
  - [Scikit-learn](https://scikit-learn.org/)
  - [PyTorch](https://pytorch.org/)
  - [HuggingFace Transformers](https://huggingface.co/)

> If you build upon this work, please consider citing it via the [`CITATION.cff`](./CITATION.cff) file.

---

## üìö Citation

If you use this work, please cite it using the metadata in [`CITATION.cff`](./CITATION.cff).

```bibtex
@software{agrawal_2025_ser,
  author = {Chirag Agrawal},
  title = {Speech Emotion Recognition},
  year = {2025},
  version = {1.0.0},
  url = {https://github.com/chirgamiyy/speech-emotion-recognition}
}
```
Feel free to ‚≠ê the repo if you found it helpful!
